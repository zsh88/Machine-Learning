{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Tweet_Dataset.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOxSCKZB4A4SwZaI31aZjxu"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wP1kH8MCXyjj",
        "outputId": "5c99aa8e-2f8a-4382-e139-a40140c12cd4"
      },
      "source": [
        "# Import pandas\n",
        "import pandas as pd\n",
        "\n",
        "# Import Twitter data as DataFrame: df\n",
        "url = 'https://assets.datacamp.com/production/repositories/463/datasets/82e9842c09ad135584521e293091c2327251121d/tweets.csv'\n",
        "df = pd.read_csv(url)\n",
        "\n",
        "# Initialize an empty dictionary: langs_count\n",
        "langs_count = {}\n",
        "\n",
        "# Extract column from DataFrame: col\n",
        "col = df['lang']\n",
        "\n",
        "# Iterate over lang column in DataFrame\n",
        "for entry in col:\n",
        "\n",
        "    # If the language is in langs_count, add 1 \n",
        "    if entry in langs_count.keys():\n",
        "        langs_count[entry] += 1\n",
        "\n",
        "    # Else add the language to langs_count, set the value to 1\n",
        "    else:\n",
        "        langs_count[entry] = 1\n",
        "# Print the populated dictionary\n",
        "print(langs_count)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'en': 97, 'et': 1, 'und': 2}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NXe4xeX7uxBv",
        "outputId": "0eeebb23-bf1c-41a0-881f-40077a507cdc"
      },
      "source": [
        "# Import pandas\n",
        "import pandas as pd\n",
        "\n",
        "# Import Twitter data as DataFrame: df\n",
        "url = 'https://assets.datacamp.com/production/repositories/463/datasets/82e9842c09ad135584521e293091c2327251121d/tweets.csv'\n",
        "tweets_df = pd.read_csv(url)\n",
        "\n",
        "# Define count_entries()\n",
        "def count_entries(df, col_name):\n",
        "    \"\"\"Return a dictionary with counts of\n",
        "    occurrences as value for each key.\"\"\"\n",
        "\n",
        "    # Initialize an empty dictionary: cols_count\n",
        "    cols_count = {}\n",
        "\n",
        "    # Extract column from DataFrame: col\n",
        "    col = df[col_name]\n",
        "    \n",
        "    # Iterate over the column in DataFrame\n",
        "    for entry in col:\n",
        "\n",
        "        # If entry is in cols_count, add 1\n",
        "        if entry in cols_count.keys():\n",
        "            cols_count[entry] += 1\n",
        "\n",
        "        # Else add the entry to cols_count, set the value to 1\n",
        "        else:\n",
        "            cols_count[entry] = 1\n",
        "\n",
        "    # Return the cols_count dictionary\n",
        "    return cols_count\n",
        "\n",
        "# Call count_entries(): result1\n",
        "result1 = count_entries(tweets_df, 'lang')\n",
        "\n",
        "# Call count_entries(): result2\n",
        "result2 = count_entries(tweets_df, 'source')\n",
        "\n",
        "# Print result1 and result2\n",
        "print(result1)\n",
        "print(result2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'en': 97, 'et': 1, 'und': 2}\n",
            "{'<a href=\"http://twitter.com\" rel=\"nofollow\">Twitter Web Client</a>': 24, '<a href=\"http://www.facebook.com/twitter\" rel=\"nofollow\">Facebook</a>': 1, '<a href=\"http://twitter.com/download/android\" rel=\"nofollow\">Twitter for Android</a>': 26, '<a href=\"http://twitter.com/download/iphone\" rel=\"nofollow\">Twitter for iPhone</a>': 33, '<a href=\"http://www.twitter.com\" rel=\"nofollow\">Twitter for BlackBerry</a>': 2, '<a href=\"http://www.google.com/\" rel=\"nofollow\">Google</a>': 2, '<a href=\"http://twitter.com/#!/download/ipad\" rel=\"nofollow\">Twitter for iPad</a>': 6, '<a href=\"http://linkis.com\" rel=\"nofollow\">Linkis.com</a>': 2, '<a href=\"http://rutracker.org/forum/viewforum.php?f=93\" rel=\"nofollow\">newzlasz</a>': 2, '<a href=\"http://ifttt.com\" rel=\"nofollow\">IFTTT</a>': 1, '<a href=\"http://www.myplume.com/\" rel=\"nofollow\">Plume\\xa0for\\xa0Android</a>': 1}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rO-bJaCbwCPe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "93b443c7-b326-4094-cb3c-b8522acf4ca2"
      },
      "source": [
        "# Define count_entries()\n",
        "def count_entries(df, *args):\n",
        "    \"\"\"Return a dictionary with counts of\n",
        "    occurrences as value for each key.\"\"\"\n",
        "    \n",
        "    #Initialize an empty dictionary: cols_count\n",
        "    cols_count = {}\n",
        "    \n",
        "    # Iterate over column names in args\n",
        "    for col_name in args:\n",
        "    \n",
        "        # Extract column from DataFrame: col\n",
        "        col = df[col_name]\n",
        "    \n",
        "        # Iterate over the column in DataFrame\n",
        "        for entry in col:\n",
        "    \n",
        "            # If entry is in cols_count, add 1\n",
        "            if entry in cols_count.keys():\n",
        "                cols_count[entry] += 1\n",
        "    \n",
        "            # Else add the entry to cols_count, set the value to 1\n",
        "            else:\n",
        "                cols_count[entry] = 1\n",
        "\n",
        "    # Return the cols_count dictionary\n",
        "    return cols_count\n",
        "\n",
        "# Call count_entries(): result1\n",
        "result1 = count_entries(tweets_df, 'lang')\n",
        "\n",
        "# Call count_entries(): result2\n",
        "result2 = count_entries(tweets_df, 'lang', 'source')\n",
        "\n",
        "# Print result1 and result2\n",
        "print(result1)\n",
        "print(result2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'en': 97, 'et': 1, 'und': 2}\n",
            "{'en': 97, 'et': 1, 'und': 2, '<a href=\"http://twitter.com\" rel=\"nofollow\">Twitter Web Client</a>': 24, '<a href=\"http://www.facebook.com/twitter\" rel=\"nofollow\">Facebook</a>': 1, '<a href=\"http://twitter.com/download/android\" rel=\"nofollow\">Twitter for Android</a>': 26, '<a href=\"http://twitter.com/download/iphone\" rel=\"nofollow\">Twitter for iPhone</a>': 33, '<a href=\"http://www.twitter.com\" rel=\"nofollow\">Twitter for BlackBerry</a>': 2, '<a href=\"http://www.google.com/\" rel=\"nofollow\">Google</a>': 2, '<a href=\"http://twitter.com/#!/download/ipad\" rel=\"nofollow\">Twitter for iPad</a>': 6, '<a href=\"http://linkis.com\" rel=\"nofollow\">Linkis.com</a>': 2, '<a href=\"http://rutracker.org/forum/viewforum.php?f=93\" rel=\"nofollow\">newzlasz</a>': 2, '<a href=\"http://ifttt.com\" rel=\"nofollow\">IFTTT</a>': 1, '<a href=\"http://www.myplume.com/\" rel=\"nofollow\">Plume\\xa0for\\xa0Android</a>': 1}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OY6BhGtkoOYC",
        "outputId": "99975634-e43f-4180-9669-f2a3de861edc"
      },
      "source": [
        "'''\n",
        "List comprehensions for time-stamped data\n",
        "100xp\n",
        "You will now make use of what you've learned from this chapter to solve a simple data\n",
        "extraction problem. You will also be introduced to a data structure, the pandas Series,\n",
        "in this exercise. We won't elaborate on it much here, but what you should know is that\n",
        "it is a data structure that you will be working with a lot of times when analyzing data\n",
        "from pandas DataFrames. You can think of DataFrame columns as single-dimension arrays\n",
        "called Series.\n",
        "In this exercise, you will be using a list comprehension to extract the time from\n",
        "time-stamped Twitter data. The pandas package has been imported as pd and the file\n",
        "'tweets.csv' has been imported as the df DataFrame for your use.\n",
        "Instructions\n",
        "-Extract the column 'created_at' from df and assign the result to tweet_time. Fun fact:\n",
        "the extracted column in tweet_time here is a Series data structure!\n",
        "-Create a list comprehension that extracts the time from each row in tweet_time. Each\n",
        "row is a string that represents a timestamp, and you will access the 12th to 19th characters in the string to extract the time. Use entry as the iterator variable and assign the result to tweet_clock_time. Remember that Python uses 0-based indexing!\n",
        "'''\n",
        "# Import packages\n",
        "import pandas as pd\n",
        "\n",
        "url = 'https://assets.datacamp.com/production/repositories/463/datasets/82e9842c09ad135584521e293091c2327251121d/tweets.csv'\n",
        "df = pd.read_csv(url)\n",
        "\n",
        "# Extract the created_at column from df: tweet_time\n",
        "tweet_time = df['created_at']\n",
        "\n",
        "# Extract the clock time: tweet_clock_time\n",
        "tweet_clock_time = [entry[11:19] for entry in tweet_time]\n",
        "\n",
        "# Print the extracted times\n",
        "print(tweet_clock_time)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['23:40:17', '23:40:17', '23:40:17', '23:40:17', '23:40:17', '23:40:17', '23:40:18', '23:40:17', '23:40:18', '23:40:18', '23:40:18', '23:40:17', '23:40:18', '23:40:18', '23:40:17', '23:40:18', '23:40:18', '23:40:17', '23:40:18', '23:40:17', '23:40:18', '23:40:18', '23:40:18', '23:40:18', '23:40:17', '23:40:18', '23:40:18', '23:40:17', '23:40:18', '23:40:18', '23:40:18', '23:40:18', '23:40:18', '23:40:18', '23:40:18', '23:40:18', '23:40:18', '23:40:18', '23:40:18', '23:40:18', '23:40:18', '23:40:18', '23:40:18', '23:40:18', '23:40:18', '23:40:18', '23:40:18', '23:40:18', '23:40:18', '23:40:18', '23:40:18', '23:40:18', '23:40:18', '23:40:18', '23:40:18', '23:40:18', '23:40:18', '23:40:18', '23:40:18', '23:40:18', '23:40:19', '23:40:18', '23:40:18', '23:40:18', '23:40:19', '23:40:19', '23:40:19', '23:40:18', '23:40:19', '23:40:19', '23:40:19', '23:40:18', '23:40:19', '23:40:19', '23:40:19', '23:40:18', '23:40:19', '23:40:19', '23:40:19', '23:40:19', '23:40:19', '23:40:19', '23:40:19', '23:40:19', '23:40:19', '23:40:19', '23:40:19', '23:40:19', '23:40:19', '23:40:19', '23:40:19', '23:40:19', '23:40:19', '23:40:19', '23:40:19', '23:40:19', '23:40:19', '23:40:19', '23:40:19', '23:40:19']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "njKsSECcob9o",
        "outputId": "af558a8a-c151-4a61-c7ad-2b57f5cf0f28"
      },
      "source": [
        "# Extract the clock time: tweet_clock_time\n",
        "tweet_clock_time = [entry[11:19] for entry in tweet_time if entry[17:19] == '19']\n",
        "\n",
        "# Print the extracted times\n",
        "print(tweet_clock_time)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['23:40:19', '23:40:19', '23:40:19', '23:40:19', '23:40:19', '23:40:19', '23:40:19', '23:40:19', '23:40:19', '23:40:19', '23:40:19', '23:40:19', '23:40:19', '23:40:19', '23:40:19', '23:40:19', '23:40:19', '23:40:19', '23:40:19', '23:40:19', '23:40:19', '23:40:19', '23:40:19', '23:40:19', '23:40:19', '23:40:19', '23:40:19', '23:40:19', '23:40:19', '23:40:19', '23:40:19', '23:40:19', '23:40:19', '23:40:19']\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}